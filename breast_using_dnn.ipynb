{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import keras \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation,Conv2D,MaxPool2D,Flatten,BatchNormalization,MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=glob(\"IDC_regular_ps50_idx5/*/*\")\n",
    "class0=[]\n",
    "class1=[]\n",
    "for i in file_path:\n",
    "\n",
    "    h=glob(i+\"/\"+\"*\")\n",
    "    if i.endswith(\"0\"):\n",
    "        for j in h:\n",
    "            class0.append(j)\n",
    "    else:\n",
    "        for j in h:\n",
    "            class1.append(j)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1=random.sample(class0,18786)\n",
    "sample2=random.sample(class1,18786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(path,class_name):\n",
    "    val=[]\n",
    "    for i in path:\n",
    "        image_data=imread(i)\n",
    "        image_size=resize(image_data,(50,50))\n",
    "        val.append([image_size,class_name])\n",
    "    \n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_breast_cancer=feature_extract(sample1,\"non_breast_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer=feature_extract(sample2,\"breast_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "combined_data=np.concatenate((non_breast_cancer,breast_cancer))\n",
    "random.seed(42)\n",
    "random.shuffle(combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for features,class_value in combined_data:\n",
    "    x.append(features)\n",
    "    y.append(class_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb=LabelEncoder()\n",
    "y=to_categorical(lb.fit_transform(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37572, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "K.clear_session()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "num_labels=y.shape[1]\n",
    "model.add(Flatten(input_shape =(50,50,3)))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"Adam\",\n",
    "loss = \"binary_crossentropy\",\n",
    "metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 15:56:41.207336: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 789000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.8395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 15:56:54.182823: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 338160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43537, saving model to breast_cancer_dnn_classification.hdf5\n",
      "822/822 [==============================] - 9s 10ms/step - loss: 0.4868 - accuracy: 0.8390 - val_loss: 0.4354 - val_accuracy: 0.8427\n",
      "Epoch 2/10\n",
      "819/822 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.8471\n",
      "Epoch 00002: val_loss improved from 0.43537 to 0.43515, saving model to breast_cancer_dnn_classification.hdf5\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4386 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 3/10\n",
      "821/822 [============================>.] - ETA: 0s - loss: 0.4356 - accuracy: 0.8471\n",
      "Epoch 00003: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4354 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 4/10\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.8470\n",
      "Epoch 00004: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4335 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 5/10\n",
      "822/822 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8472\n",
      "Epoch 00005: val_loss improved from 0.43515 to 0.43515, saving model to breast_cancer_dnn_classification.hdf5\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4324 - accuracy: 0.8472 - val_loss: 0.4351 - val_accuracy: 0.8427\n",
      "Epoch 6/10\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.4313 - accuracy: 0.8471\n",
      "Epoch 00006: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4311 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 7/10\n",
      "818/822 [============================>.] - ETA: 0s - loss: 0.4300 - accuracy: 0.8475\n",
      "Epoch 00007: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4306 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 8/10\n",
      "815/822 [============================>.] - ETA: 0s - loss: 0.4294 - accuracy: 0.8473\n",
      "Epoch 00008: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4296 - accuracy: 0.8472 - val_loss: 0.4353 - val_accuracy: 0.8427\n",
      "Epoch 9/10\n",
      "816/822 [============================>.] - ETA: 0s - loss: 0.4294 - accuracy: 0.8469\n",
      "Epoch 00009: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4290 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 10/10\n",
      "820/822 [============================>.] - ETA: 0s - loss: 0.4286 - accuracy: 0.8472\n",
      "Epoch 00010: val_loss did not improve from 0.43515\n",
      "822/822 [==============================] - 6s 8ms/step - loss: 0.4287 - accuracy: 0.8472 - val_loss: 0.4352 - val_accuracy: 0.8427\n"
     ]
    }
   ],
   "source": [
    "num_epochs =10\n",
    "num_batch_size =22\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='breast_cancer_dnn_classification.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history= model.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
